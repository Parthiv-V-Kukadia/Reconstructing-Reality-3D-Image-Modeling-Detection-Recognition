# -*- coding: utf-8 -*-
"""Detection_Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yJJ-0AGiYiwEKs08rgGnj3volPybdVWj

# Image Detection and Classification of a Chair and Dining Table
We will be using a COCO dataset, and will begin by loading and preparing the COCO dataset

### Import the necessary toolboxes
"""

!pip install ultralytics
#!pip install --upgrade --force-reinstall ultralytics

# To load COCO dataset
import torchvision
from torchvision.datasets import CocoDetection
from torchvision.transforms import ToTensor
from pycocotools.coco import COCO
from google.colab import drive
drive.mount('/content/drive')

# To train YOLOv8
import json
import yaml
import os
import ultralytics
from ultralytics import YOLO
import shutil
import random

# To train ResNet
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torchvision import transforms, datasets
import cv2
from glob import glob
from torch.utils.data import DataLoader
from torchvision import models
from tqdm import tqdm
import torch.nn.functional as F
from PIL import Image
from google.colab.patches import cv2_imshow
import numpy as np

# To apply Non-Max Supression
from torchvision.ops import nms

# To voxelize and remove outliers
#import open3d as o3d

# To evaluate the model
from sklearn.metrics import f1_score, average_precision_score

# Check if GPU is available
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

"""### Load COCO Dataset"""

# Define dataset directory in Google Drive
drive_root = '/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/'  # Update path if needed

# Load COCO dataset from Google Drive
train_dataset = CocoDetection(
    root=os.path.join(drive_root, 'images/subset6000_both_train2017'),
    annFile=os.path.join(drive_root, 'annotations/subset6000_both_filtered_instances_train2017.json'),
    transform=ToTensor()
)
val_dataset = CocoDetection(
    root=os.path.join(drive_root, 'images/subset250_both_val2017'),
    annFile=os.path.join(drive_root, 'annotations/subset250_both_filtered_instances_val2017.json'),
    transform=ToTensor()
)


# Print dataset sizes
print(f"Train dataset: {len(train_dataset)} images")
print(f"Val dataset: {len(val_dataset)} images")

"""### Convert COCO annotations to YOLO Labels
** (Don't need to re-run as necessary files have already been created)
"""

### Filter COCO annotations to only include chair and dining table ###

# Load the original filtered COCO annotations
with open('coco/annotations/instances_train2017.json', 'r') as f:
    train_data = json.load(f)

with open('coco/annotations/instances_val2017.json', 'r') as f:
    val_data = json.load(f)

# Define the class IDs you want to keep
class_ids = [62, 67]  # Chair and Dining Table

# Function to filter annotations
def filter_annotations(data, class_ids):
    # Filter categories
    data['categories'] = [cat for cat in data['categories'] if cat['id'] in class_ids]

    # Filter annotations
    data['annotations'] = [ann for ann in data['annotations'] if ann['category_id'] in class_ids]

    # Filter images (keep only images with relevant annotations)
    valid_image_ids = set(ann['image_id'] for ann in data['annotations'])
    data['images'] = [img for img in data['images'] if img['id'] in valid_image_ids]

    return data

# Filter train and val annotations
filtered_train_data = filter_annotations(train_data, class_ids)
filtered_val_data = filter_annotations(val_data, class_ids)

# Save the filtered annotations
with open('coco/annotations/filtered_instances_train2017.json', 'w') as f:
    json.dump(filtered_train_data, f)

with open('coco/annotations/filtered_instances_val2017.json', 'w') as f:
    json.dump(filtered_val_data, f)

### Create a subset of the filtered chairs and dining tables to train the model ###

def create_subset(original_images_dir, original_annotations_file, subset_images_dir, subset_annotations_file, chair_count, table_count):
    # Create subset directory if it doesn't exist
    os.makedirs(subset_images_dir, exist_ok=True)

    # Load filtered annotations
    with open(original_annotations_file, 'r') as f:
        annotations_data = json.load(f)

    # Get category IDs dynamically
    category_ids = {cat["name"]: cat["id"] for cat in annotations_data.get("categories", [])}

    # Ensure chairs and dining tables exist in the dataset
    if "chair" not in category_ids or "dining table" not in category_ids:
        raise ValueError("Category names 'chair' and 'dining table' not found in annotations.")

    CHAIR_ID = category_ids["chair"]
    TABLE_ID = category_ids["dining table"]

    # Filter annotations
    chair_annotations = [ann for ann in annotations_data["annotations"] if ann["category_id"] == CHAIR_ID]
    dining_table_annotations = [ann for ann in annotations_data["annotations"] if ann["category_id"] == TABLE_ID]

    # Ensure sufficient data
    if len(chair_annotations) < chair_count or len(dining_table_annotations) < table_count:
        raise ValueError(f"Not enough annotations to extract {chair_count} chairs and {table_count} dining tables.")

    # Randomly select the required number of chair and dining table annotations
    selected_annotations = random.sample(chair_annotations, chair_count) + random.sample(dining_table_annotations, table_count)

    # Count instances per image
    image_instances = {}
    for ann in selected_annotations:
        image_instances[ann["image_id"]] = image_instances.get(ann["image_id"], 0) + 1

    # Keep only images that actually contain these instances
    selected_image_ids = set(image_instances.keys())
    selected_images = [img for img in annotations_data["images"] if img["id"] in selected_image_ids]

    # Copy selected images
    for img in selected_images:
        src = os.path.join(original_images_dir, img["file_name"])
        dst = os.path.join(subset_images_dir, img["file_name"])
        if os.path.exists(src):
            shutil.copy(src, dst)

    # Only keep annotations whose image exists in the final subset
    final_image_ids = {img["id"] for img in selected_images}
    filtered_annotations = [ann for ann in selected_annotations if ann["image_id"] in final_image_ids]

    # Save the final subset
    subset_annotations = {
        "categories": annotations_data["categories"],  # Keep the category structure
        "images": selected_images,
        "annotations": filtered_annotations
    }

    # Save the subset annotations
    with open(subset_annotations_file, 'w') as f:
        json.dump(subset_annotations, f, indent=4)

    print(f"Subset created with {len(selected_images)} images.")
    print(f"Annotations saved: {len(filtered_annotations)} ({chair_count} chairs, {table_count} dining tables)")


# Define paths for the training subset
original_images_train_dir = 'coco/images/train2017'  # Directory containing all images
original_annotations_train_file = 'coco/annotations/filtered_instances_train2017.json'  # Path to filtered annotations
subset_images_train_dir = 'coco/images/subset250_train2017'  # Directory to save subset images
subset_annotations_train_file = 'coco/annotations/subset250_filtered_instances_train2017.json'  # Path to save subset annotations

# Create training subset
create_subset(original_images_train_dir, original_annotations_train_file, subset_images_train_dir, subset_annotations_train_file, 300, 200)

# Define paths for the validation subset
original_images_val_dir = 'coco/images/val2017'  # Directory containing all images
original_annotations_val_file = 'coco/annotations/filtered_instances_val2017.json'  # Path to filtered annotations
subset_images_val_dir = 'coco/images/subset250_val2017'  # Directory to save subset images
subset_annotations_val_file = 'coco/annotations/subset250_filtered_instances_val2017.json'  # Path to save subset annotations

# Create validation subset
create_subset(original_images_val_dir, original_annotations_val_file, subset_images_val_dir, subset_annotations_val_file, 350, 250)

### Convert COCO annotations to YOLO Labels ###

# Function to create YOLO labels for a given COCO dataset.

def create_yolo_labels(coco_json, output_dir, class_ids, yolo_class_mapping):
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    # Load COCO annotations
    coco = COCO(coco_json)

    # Iterate through all images in the dataset
    image_ids = coco.getImgIds()
    for image_id in image_ids:
        # Get image info
        image_info = coco.loadImgs(image_id)[0]
        image_width = image_info['width']
        image_height = image_info['height']
        image_filename = image_info['file_name']

        # Get all annotations for the current image
        annotation_ids = coco.getAnnIds(imgIds=image_id, catIds=class_ids)
        annotations = coco.loadAnns(annotation_ids)

        # Prepare YOLO label file
        yolo_labels = []
        for ann in annotations:
            # Get class ID and map to YOLO class ID
            coco_class_id = ann['category_id']
            yolo_class_id = yolo_class_mapping[coco_class_id]

            # Get bounding box in COCO format [x_min, y_min, width, height]
            bbox = ann['bbox']
            x_min, y_min, width, height = bbox

            # Convert COCO bbox to YOLO format [x_center, y_center, width, height] (normalized)
            x_center = (x_min + width / 2) / image_width
            y_center = (y_min + height / 2) / image_height
            width_norm = width / image_width
            height_norm = height / image_height

            # Append to YOLO labels
            yolo_labels.append(f"{yolo_class_id} {x_center} {y_center} {width_norm} {height_norm}")

        # Save YOLO labels to a .txt file
        if yolo_labels:
            label_filename = os.path.splitext(image_filename)[0] + '.txt'
            label_filepath = os.path.join(output_dir, label_filename)
            with open(label_filepath, 'w') as f:
                f.write('\n'.join(yolo_labels))


# Define paths and class mappings for training, validation, and test data
train_coco_json = 'coco/annotations/subset250_filtered_instances_train2017.json'  # Path to training COCO annotations JSON file
train_output_dir = "/Users/parthivkukadia/OneDrive - National University of Singapore/ME6402 Project/coco/labels/subset250_train2017/"  # Directory to save YOLO label files for training

val_coco_json = 'coco/annotations/subset250_filtered_instances_val2017.json'  # Path to validation COCO annotations JSON file
val_output_dir = "/Users/parthivkukadia/OneDrive - National University of Singapore/ME6402 Project/coco/labels/subset250_val2017/"  # Directory to save YOLO label files for validation

# Class IDs for chair and dining table
class_ids = [62, 67]  # COCO class IDs for chair and dining table
yolo_class_mapping = {62: 0, 67: 1}  # Map COCO class IDs to YOLO class IDs

# Create YOLO labels for training, validation, and test datasets
create_yolo_labels(train_coco_json, train_output_dir, class_ids, yolo_class_mapping)
create_yolo_labels(val_coco_json, val_output_dir, class_ids, yolo_class_mapping)

print("YOLO label files have been created for training, validation, and test datasets.")

"""### Train Yolov8 Model for Object Detection of Both Chairs and Dining Tables
** (only showing best one before pivot in methodology - appendix shows additional trials Performed)

Trial 57: Changed train subset to 250 chairs, 200 dining tables, Validation subset to 350 chairs and 350 dining tables, Included augmentation settings into the results_model instead of custom_coco, enabled cos_lr=True.
"""

### Trial 57 ###

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8s.pt') # runs/detect/train43/weights/best.pt

results = model.train(
    data='coco/custom_coco.yaml',
    epochs=50,  # Increase epochs for longer training
    imgsz=620,  # Try reducing image size if NMS issues persist
    batch=8,  # Reduce batch size to prevent memory overload
    device="mps",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=100,  # Lower max detections per image to avoid NMS time limits, prev = 100
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.5,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.001,  # Lower learning rate to avoid overshooting
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=10,
    translate=0.1,
    scale=0.5,
    flipud=0.0,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.1,
)

### Trial 57: Compare trained model best.pt with YOLO8s.pt ###
# Load the original model
model_original = YOLO('yolov8s.pt')
metrics_original = model_original.val(data='coco/custom_coco.yaml')

# Load the best checkpoint from train56
model_train58 = YOLO('runs/detect/train58/weights/best.pt')
metrics_train58 = model_train58.val(data='coco/custom_coco.yaml')

# Compare mAP50
print(f"Original mAP50: {metrics_original.box.map50}")
print(f"Train56 mAP50: {metrics_train58.box.map50}")

"""### Training YOLO Model with Just Chairs

#### Filter subset of chairs annotations and images, and create YOLO Labels
** (Don't need to re-run as necessary files have already been created)
"""

### Filter COCO annotations and Images to only include chairs ###


def create_subset(original_images_dir, original_annotations_file, subset_images_dir, subset_annotations_file, category_name="chair", num_samples=3000):
    # Create subset directory if it doesn't exist
    os.makedirs(subset_images_dir, exist_ok=True)

    # Load filtered annotations
    with open(original_annotations_file, 'r') as f:
        annotations_data = json.load(f)

    # Get category IDs dynamically
    category_ids = {cat["name"]: cat["id"] for cat in annotations_data.get("categories", [])}

    # Ensure the desired category exists in the dataset
    if category_name not in category_ids:
        raise ValueError(f"Category name '{category_name}' not found in annotations.")

    category_id = category_ids[category_name]

    # Filter category annotations
    category_annotations = [ann for ann in annotations_data["annotations"] if ann["category_id"] == category_id]

    # Get unique image IDs containing the category
    category_image_ids = list({ann["image_id"] for ann in category_annotations})

    # Debugging info
    print(f"Total images in dataset: {len(annotations_data['images'])}")
    print(f"Total annotations in dataset: {len(annotations_data['annotations'])}")
    print(f"Total '{category_name}' annotations: {len(category_annotations)}")
    print(f"Total images with '{category_name}': {len(category_image_ids)}")

    # Ensure there are enough unique images
    num_images_to_select = min(num_samples, len(category_image_ids))

    if num_images_to_select == 0:
        raise ValueError(f"No images found with category '{category_name}'.")

    # Randomly select up to num_samples unique images
    selected_image_ids = set(random.sample(category_image_ids, num_images_to_select))

    # Select all annotations related to these images
    filtered_annotations = [ann for ann in category_annotations if ann["image_id"] in selected_image_ids]
    selected_images = [img for img in annotations_data["images"] if img["id"] in selected_image_ids]

    # Copy selected images
    for img in selected_images:
        src = os.path.join(original_images_dir, img["file_name"])
        dst = os.path.join(subset_images_dir, img["file_name"])
        if os.path.exists(src):
            shutil.copy(src, dst)

    # Save the final subset
    subset_annotations = {
        "categories": annotations_data["categories"],  # Keep the category structure
        "images": selected_images,
        "annotations": filtered_annotations
    }

    # Save the subset annotations
    with open(subset_annotations_file, 'w') as f:
        json.dump(subset_annotations, f, indent=4)

    print(f"Final subset: {len(selected_images)} images, {len(filtered_annotations)} annotations")
    print(f"Subset created with {len(selected_images)} images.")
    print(f"Annotations saved: {len(filtered_annotations)} ({len(filtered_annotations)} {category_name}s)")

# Define paths for training and validation datasets
# Validation Data
create_subset(
    original_images_dir='coco/images/val2017',
    original_annotations_file='coco/annotations/filtered_instances_val2017.json',
    subset_images_dir='coco/images/subset3000_chairs_val2017',
    subset_annotations_file='coco/annotations/subset3000_chairs_filtered_instances_val2017.json'
)

# Training Data
create_subset(
    original_images_dir='coco/images/train2017',
    original_annotations_file='coco/annotations/filtered_instances_train2017.json',
    subset_images_dir='coco/images/subset3000_chairs_train2017',
    subset_annotations_file='coco/annotations/subset3000_chairs_filtered_instances_train2017.json'
)

### Create Labels for Filtered Chair's Subset ###

# Define the paths and categories for both training and validation datasets
datasets = [
    {
        "coco_json": 'coco/annotations/subset3000_chairs_filtered_instances_train2017.json',  # Path to training dataset annotations
        "output_dir": "/Users/parthivkukadia/OneDrive - National University of Singapore/ME6402 Project/coco/labels/subset3000_chairs_train2017/"  # Directory to save YOLO labels for training
    },
    {
        "coco_json": 'coco/annotations/subset3000_chairs_filtered_instances_val2017.json',  # Path to validation dataset annotations
        "output_dir": "/Users/parthivkukadia/OneDrive - National University of Singapore/ME6402 Project/coco/labels/subset3000_chairs_val2017/"  # Directory to save YOLO labels for validation
    }
]

# Define the class IDs for chair and dining table
class_ids = [62]  # COCO class IDs for chair
yolo_class_mapping = {62: 0}  # Map COCO class IDs to YOLO class IDs

# Iterate over the datasets (training and validation)
for dataset in datasets:
    coco_json = dataset["coco_json"]
    output_dir = dataset["output_dir"]

    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    # Load COCO annotations
    coco = COCO(coco_json)

    # Iterate through all images in the dataset
    image_ids = coco.getImgIds()
    for image_id in image_ids:
        # Get image info
        image_info = coco.loadImgs(image_id)[0]
        image_width = image_info['width']
        image_height = image_info['height']
        image_filename = image_info['file_name']

        # Get all annotations for the current image
        annotation_ids = coco.getAnnIds(imgIds=image_id, catIds=class_ids)
        annotations = coco.loadAnns(annotation_ids)

        # Prepare YOLO label file
        yolo_labels = []
        for ann in annotations:
            # Get class ID and map to YOLO class ID
            coco_class_id = ann['category_id']
            yolo_class_id = yolo_class_mapping[coco_class_id]

            # Get bounding box in COCO format [x_min, y_min, width, height]
            bbox = ann['bbox']
            x_min, y_min, width, height = bbox

            # Convert COCO bbox to YOLO format [x_center, y_center, width, height] (normalized)
            x_center = (x_min + width / 2) / image_width
            y_center = (y_min + height / 2) / image_height
            width_norm = width / image_width
            height_norm = height / image_height

            # Append to YOLO labels
            yolo_labels.append(f"{yolo_class_id} {x_center} {y_center} {width_norm} {height_norm}")

        # Save YOLO labels to a .txt file
        if yolo_labels:
            label_filename = os.path.splitext(image_filename)[0] + '.txt'
            label_filepath = os.path.join(output_dir, label_filename)
            with open(label_filepath, 'w') as f:
                f.write('\n'.join(yolo_labels))

    print(f"YOLO labels for {output_dir} saved successfully.")

"""#### Trial 70 - Best YOLO trained model for Chairs
Increase conf, and train with Yolov8x model, with 3000 images
"""

### Trial 70 - Best Chairs Model (Final) ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8x') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=150,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=200,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=4,
    conf=0.6,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.5,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=20,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.6,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    box=0.5,  # Reduced bounding box loss gain
    patience=35, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_chairs_val2017/000000000139.jpg')
results = model.predict(source=image_path, conf=0.25)
results[0].show()  # Access the first result and show the image

"""### Training Model with just Dining Tables
instead of training dining tables on top of chairs, to see if it provides a more robust detection system

#### Filter subset of dining table annotations and images, and create YOLO Labels
** (Don't need to re-run as necessary files have already been created)
"""

### Filter COCO annotations and Images to only include dining tables ###


def create_subset(original_images_dir, original_annotations_file, subset_images_dir, subset_annotations_file, category_name="dining table", num_samples=3000):
    # Create subset directory if it doesn't exist
    os.makedirs(subset_images_dir, exist_ok=True)

    # Load filtered annotations
    with open(original_annotations_file, 'r') as f:
        annotations_data = json.load(f)

    # Get category IDs dynamically
    category_ids = {cat["name"]: cat["id"] for cat in annotations_data.get("categories", [])}

    # Ensure the desired category exists in the dataset
    if category_name not in category_ids:
        raise ValueError(f"Category name '{category_name}' not found in annotations.")

    category_id = category_ids[category_name]

    # Filter category annotations
    category_annotations = [ann for ann in annotations_data["annotations"] if ann["category_id"] == category_id]

    # Get unique image IDs containing the category
    category_image_ids = list({ann["image_id"] for ann in category_annotations})

    # Debugging info
    print(f"Total images in dataset: {len(annotations_data['images'])}")
    print(f"Total annotations in dataset: {len(annotations_data['annotations'])}")
    print(f"Total '{category_name}' annotations: {len(category_annotations)}")
    print(f"Total images with '{category_name}': {len(category_image_ids)}")

    # Ensure there are enough unique images
    num_images_to_select = min(num_samples, len(category_image_ids))

    if num_images_to_select == 0:
        raise ValueError(f"No images found with category '{category_name}'.")

    # Randomly select up to num_samples unique images
    selected_image_ids = set(random.sample(category_image_ids, num_images_to_select))

    # Select all annotations related to these images
    filtered_annotations = [ann for ann in category_annotations if ann["image_id"] in selected_image_ids]
    selected_images = [img for img in annotations_data["images"] if img["id"] in selected_image_ids]

    # Copy selected images
    for img in selected_images:
        src = os.path.join(original_images_dir, img["file_name"])
        dst = os.path.join(subset_images_dir, img["file_name"])
        if os.path.exists(src):
            shutil.copy(src, dst)

    # Save the final subset
    subset_annotations = {
        "categories": annotations_data["categories"],  # Keep the category structure
        "images": selected_images,
        "annotations": filtered_annotations
    }

    # Save the subset annotations
    with open(subset_annotations_file, 'w') as f:
        json.dump(subset_annotations, f, indent=4)

    print(f"Final subset: {len(selected_images)} images, {len(filtered_annotations)} annotations")
    print(f"Subset created with {len(selected_images)} images.")
    print(f"Annotations saved: {len(filtered_annotations)} ({len(filtered_annotations)} {category_name}s)")

# Define paths for training and validation datasets
# Validation Data
create_subset(
    original_images_dir='coco/images/val2017',
    original_annotations_file='coco/annotations/filtered_instances_val2017.json',
    subset_images_dir='coco/images/subset3000_tables_val2017',
    subset_annotations_file='coco/annotations/subset3000_tables_filtered_instances_val2017.json'
)

# Training Data
create_subset(
    original_images_dir='coco/images/train2017',
    original_annotations_file='coco/annotations/filtered_instances_train2017.json',
    subset_images_dir='coco/images/subset3000_tables_train2017',
    subset_annotations_file='coco/annotations/subset3000_tables_filtered_instances_train2017.json'
)

### Create Labels for Filtered Dining Table's Subset ###

# Define the paths and categories for both training and validation datasets
datasets = [
    {
        "coco_json": 'coco/annotations/subset3000_tables_filtered_instances_train2017.json',  # Path to training dataset annotations
        "output_dir": "/Users/parthivkukadia/OneDrive - National University of Singapore/ME6402 Project/coco/labels/subset3000_tables_train2017/"  # Directory to save YOLO labels for training
    },
    {
        "coco_json": 'coco/annotations/subset3000_tables_filtered_instances_val2017.json',  # Path to validation dataset annotations
        "output_dir": "/Users/parthivkukadia/OneDrive - National University of Singapore/ME6402 Project/coco/labels/subset3000_tables_val2017/"  # Directory to save YOLO labels for validation
    }
]

# Define the class IDs for chair and dining table
class_ids = [67]  # COCO class IDs for chair
yolo_class_mapping = {67: 0}  # Map COCO class IDs to YOLO class IDs

# Iterate over the datasets (training and validation)
for dataset in datasets:
    coco_json = dataset["coco_json"]
    output_dir = dataset["output_dir"]

    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    # Load COCO annotations
    coco = COCO(coco_json)

    # Iterate through all images in the dataset
    image_ids = coco.getImgIds()
    for image_id in image_ids:
        # Get image info
        image_info = coco.loadImgs(image_id)[0]
        image_width = image_info['width']
        image_height = image_info['height']
        image_filename = image_info['file_name']

        # Get all annotations for the current image
        annotation_ids = coco.getAnnIds(imgIds=image_id, catIds=class_ids)
        annotations = coco.loadAnns(annotation_ids)

        # Prepare YOLO label file
        yolo_labels = []
        for ann in annotations:
            # Get class ID and map to YOLO class ID
            coco_class_id = ann['category_id']
            yolo_class_id = yolo_class_mapping[coco_class_id]

            # Get bounding box in COCO format [x_min, y_min, width, height]
            bbox = ann['bbox']
            x_min, y_min, width, height = bbox

            # Convert COCO bbox to YOLO format [x_center, y_center, width, height] (normalized)
            x_center = (x_min + width / 2) / image_width
            y_center = (y_min + height / 2) / image_height
            width_norm = width / image_width
            height_norm = height / image_height

            # Append to YOLO labels
            yolo_labels.append(f"{yolo_class_id} {x_center} {y_center} {width_norm} {height_norm}")

        # Save YOLO labels to a .txt file
        if yolo_labels:
            label_filename = os.path.splitext(image_filename)[0] + '.txt'
            label_filepath = os.path.join(output_dir, label_filename)
            with open(label_filepath, 'w') as f:
                f.write('\n'.join(yolo_labels))

    print(f"YOLO labels for {output_dir} saved successfully.")

"""#### Trial 74 - more data augmentation - BEST"""

### Trial 74 ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8x') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "table_coco.yaml"),
    epochs=175,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=200,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=14,
    conf=0.75,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.5,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=45,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.6,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    box=0.5,  # Reduced bounding box loss gain
    patience=40, # Number of epochs with no improvement before stopping (increase or decrease)
    #save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_both_val2017/000000000139.jpg') ### Try Mosaic for validation testing
results = model.predict(source=image_path, conf=0.3)
results[0].show()  # Access the first result and show the image

"""### Train ResNet for Classification
We will load a pre-trained ResNet model and fine-tune it
"""

# Load the trained YOLO models
yolo_chair_model = YOLO("/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best_chair/weights/best.pt")
yolo_table_model = YOLO("/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best_table/weights/best.pt")

# Define dataset paths
train_images_path = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/images/subset6000_both_train2017"
val_images_path = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/images/subset250_both_val2017"

# Output directories for cropped images
train_crops_dir = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/images/cropped/train"
val_crops_dir = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/images/cropped/val"
os.makedirs(train_crops_dir, exist_ok=True)
os.makedirs(val_crops_dir, exist_ok=True)

# Function to process images using both models
def process_images(image_folder, save_crops_dir):
    image_paths = glob(os.path.join(image_folder, "*.jpg"))
    for img_path in image_paths:
        image = cv2.imread(img_path)

        # Run detection with chair model
        chair_results = yolo_chair_model(img_path)
        for result in chair_results:
            boxes = result.boxes.xyxy.cpu().numpy()
            for i, box in enumerate(boxes):
                x1, y1, x2, y2 = map(int, box)
                cropped_obj = image[y1:y2, x1:x2]
                class_dir = os.path.join(save_crops_dir, "chair")
                os.makedirs(class_dir, exist_ok=True)
                filename = f"{os.path.basename(img_path).split('.')[0]}_chair_{i}.jpg"
                cv2.imwrite(os.path.join(class_dir, filename), cropped_obj)

        # Run detection with table model
        table_results = yolo_table_model(img_path)
        for result in table_results:
            boxes = result.boxes.xyxy.cpu().numpy()
            for i, box in enumerate(boxes):
                x1, y1, x2, y2 = map(int, box)
                cropped_obj = image[y1:y2, x1:x2]
                class_dir = os.path.join(save_crops_dir, "dining_table")
                os.makedirs(class_dir, exist_ok=True)
                filename = f"{os.path.basename(img_path).split('.')[0]}_table_{i}.jpg"
                cv2.imwrite(os.path.join(class_dir, filename), cropped_obj)

# Run YOLO detection and crop images
process_images(train_images_path, train_crops_dir)
process_images(val_images_path, val_crops_dir)

# Device setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define transformations
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),  # <- Added
    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # <- Added
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Load train and validation datasets
train_dataset = datasets.ImageFolder(root=train_crops_dir, transform=train_transform)
val_dataset = datasets.ImageFolder(root=val_crops_dir, transform=val_transform)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)


# Print class mapping (optional, for verification)
print("Class to index mapping:", train_dataset.class_to_idx)
print(train_dataset.classes)  # ['chair', 'dining_table']

# Load pre-trained ResNet50
resnet = models.resnet50(pretrained=True)

# Replace the final classification layer to match 2 classes
resnet.fc = nn.Linear(resnet.fc.in_features, 2)  # Classes: chair and dining_table

# Move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet.to(device)

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(resnet.parameters(), lr=1e-4, weight_decay=1e-4)

# Training configuration
num_epochs = 10

# Training and validation loop
for epoch in range(num_epochs):
    resnet.train()
    running_loss = 0.0
    correct = 0
    total = 0

    print(f"\nEpoch [{epoch+1}/{num_epochs}]")

    for images, labels in tqdm(train_loader, desc="Training"):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = resnet(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_accuracy = 100 * correct / total
    train_loss = running_loss / len(train_loader)
    print(f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%")

    # Validation
    resnet.eval()
    val_correct = 0
    val_total = 0
    val_loss = 0.0

    with torch.no_grad():
        for val_images, val_labels in tqdm(val_loader, desc="Validating"):
            val_images, val_labels = val_images.to(device), val_labels.to(device)
            val_outputs = resnet(val_images)
            loss = criterion(val_outputs, val_labels)

            val_loss += loss.item()
            _, val_predicted = torch.max(val_outputs, 1)
            val_correct += (val_predicted == val_labels).sum().item()
            val_total += val_labels.size(0)

    val_accuracy = 100 * val_correct / val_total
    val_loss_avg = val_loss / len(val_loader)
    print(f"Val Loss: {val_loss_avg:.4f}, Val Accuracy: {val_accuracy:.2f}%")

# Save the trained model
model_path = "resnet50_chair_table.pth"
torch.save(resnet.state_dict(), model_path)
print(f"\nTraining complete! Model saved to {model_path}")

# Create a save path for best model
save_path = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/best_resnet_model.pth"
best_val_acc = 0.0

# Set model to evaluation
resnet.eval()
correct_top1 = 0
total = 0

# Assuming you have 2 classes: chair (0), dining_table (1)
num_classes = 2
class_correct = [0 for _ in range(num_classes)]
class_total = [0 for _ in range(num_classes)]

with torch.no_grad():
    for images, labels in tqdm(val_loader, desc="Validating"):
        images, labels = images.to(device), labels.to(device)
        outputs = resnet(images)

        # Top-1 prediction
        _, predicted = torch.max(outputs, 1)
        correct_top1 += (predicted == labels).sum().item()

        total += labels.size(0)

        # Per-class accuracy tracking
        for i in range(labels.size(0)):
            label = labels[i]
            class_total[label] += 1
            if predicted[i] == label:
                class_correct[label] += 1

# Overall Top-1 accuracy
accuracy_top1 = 100 * correct_top1 / total

print(f"\nValidation Accuracy (Top-1): {accuracy_top1:.2f}%")

# Per-class accuracy
class_names = train_dataset.classes  # ["chair", "dining_table"]
print("\nPer-Class Accuracy:")
for i in range(num_classes):
    acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0
    print(f"{class_names[i]}: {acc:.2f}%")

# Save best model
if accuracy_top1 > best_val_acc:
    best_val_acc = accuracy_top1
    torch.save(resnet.state_dict(), save_path)
    print(f"\nâœ… Best model saved with {accuracy_top1:.2f}% accuracy to: {save_path}")
else:
    print("\nNo improvement, model not saved.")

"""### Testing Yolo and Resnet on a Random image"""

# Load YOLO models for chairs and tables
yolo_chair_model = YOLO("/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best_chair/weights/best.pt")
yolo_table_model = YOLO("/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best_table/weights/best.pt")

# Load ResNet for classification
resnet = models.resnet50(pretrained=True)
resnet.fc = torch.nn.Linear(resnet.fc.in_features, 2)  # 2 classes: chair, dining table
resnet.load_state_dict(torch.load("/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/best_resnet_model.pth"
))
resnet.eval()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet.to(device)

"""Process the Validation Image with YOLO for Object Detection"""

# Define the image transformation for ResNet
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Image path
image_path = os.path.join(drive_root, 'images/subset250_both_val2017/000000000139.jpg')

# Run detection using YOLO models
results_chair = yolo_chair_model.predict(source=image_path, conf=0.3)
results_table = yolo_table_model.predict(source=image_path, conf=0.3)

# Extract YOLO results (bounding boxes and class IDs)
chairs_boxes = results_chair[0].boxes.xyxy.cpu().numpy()
tables_boxes = results_table[0].boxes.xyxy.cpu().numpy()

"""Crop and Classify Detected Objects Using Resent"""

# Function to classify detected objects using ResNet
def classify_object(cropped_obj):
    # Convert numpy array to PIL image
    cropped_obj = Image.fromarray(cv2.cvtColor(cropped_obj, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB and to PIL image
    cropped_obj = transform(cropped_obj).unsqueeze(0)  # Apply transformation and add batch dimension
    cropped_obj = cropped_obj.to(device)

    with torch.no_grad():
        outputs = resnet(cropped_obj)
        _, predicted = torch.max(outputs, 1)  # Get the predicted class
        return predicted.item()

# Load the image for visualization
image = cv2.imread(image_path)

# Process detected chairs
for box in chairs_boxes:
    x1, y1, x2, y2 = map(int, box)  # Get bounding box coordinates
    cropped_obj = image[y1:y2, x1:x2]  # Crop the object from the image
    chair_class = classify_object(cropped_obj)  # Classify using ResNet

    # Draw bounding box and label
    color = (0, 255, 0)  # Green for chair
    label = "chair" if chair_class == 0 else "dining_table"
    image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
    image = cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# Process detected tables
for box in tables_boxes:
    x1, y1, x2, y2 = map(int, box)  # Get bounding box coordinates
    cropped_obj = image[y1:y2, x1:x2]  # Crop the object from the image
    table_class = classify_object(cropped_obj)  # Classify using ResNet

    # Draw bounding box and label
    color = (0, 0, 255)  # Red for table
    label = "chair" if table_class == 0 else "dining_table"
    image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
    image = cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# Show the image with bounding boxes and labels
# Show the image with bounding boxes and labels
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Optionally, save the image
cv2.imwrite("/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detection_results.jpg", image)

"""#### Evaluate the Model"""

# Function to calculate Top-1 accuracy
def top_k_accuracy(predictions, ground_truth, k=1):
    predictions = predictions.view(-1)
    ground_truth = ground_truth.view(-1)
    predictions = predictions.unsqueeze(1)

    top_k_preds = predictions.topk(k, dim=1)[1]
    correct = top_k_preds.eq(ground_truth.view(-1, 1).expand_as(top_k_preds))
    correct_k = correct.sum().item()
    return correct_k / predictions.size(0)

# Convert lists to tensors
predictions_tensor = torch.tensor(predictions_list)
ground_truth_tensor = torch.tensor(ground_truth_list)

# Calculate Top-1 accuracy
top1_accuracy = top_k_accuracy(predictions_tensor, ground_truth_tensor, k=1)
print(f"Top-1 Accuracy: {top1_accuracy*100:.2f}%")

# Calculate F1 score
f1 = f1_score(ground_truth_tensor.numpy(), predictions_tensor.numpy(), average='weighted')
print(f"F1 Score: {f1:.2f}")

# Calculate mAP (mean Average Precision)
ap_scores = []
num_classes = len(set(ground_truth_tensor.numpy()))  # Assuming ground truth contains class labels
for i in range(num_classes):
    ap = average_precision_score(ground_truth_tensor.numpy() == i, predictions_tensor.numpy() == i)
    ap_scores.append(ap)

mAP = sum(ap_scores) / len(ap_scores)
print(f"mAP: {mAP:.2f}")

"""### Integrating Detection and Classification into 3D reconstruction

#### Object Refinement
Voxelization and outlier removal using open3d
"""

# 'point_cloud' is our 3D reconstructed point cloud
pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(point_cloud)

# Voxel downsampling
voxel_down_pcd = pcd.voxel_down_sample(voxel_size=0.05)

# Remove the outliers
cl, ind = voxel_down_pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)
inlier_cloud = voxel_down_pcd.select_by_index(ind)

"""#### Running the model on 3D reconstructed Image"""

# Point_cloud is the 3D reconstructed point cloud
# Project 3D points to 2D (e.g., using a simple orthographic projection or depth map)
depth_map = project_to_2d(point_cloud)  # Implement this function depending on your requirements

# Use the 2D depth map to run the model
results = model(depth_map)

"""#### Evaluating the model
We will use metrics like mAP, Top-1 accuracy, and F1-Score
"""

# Function to calculate Top-1 accuracy
def top_k_accuracy(predictions, ground_truth, k=1):
    predictions = predictions.view(-1)
    ground_truth = ground_truth.view(-1)
    predictions = predictions.unsqueeze(1)

    top_k_preds = predictions.topk(k, dim=1)[1]
    correct = top_k_preds.eq(ground_truth.view(-1, 1).expand_as(top_k_preds))
    correct_k = correct.sum().item()
    return correct_k / predictions.size(0)

# Convert lists to tensors
predictions_tensor = torch.tensor(predictions_list)
ground_truth_tensor = torch.tensor(ground_truth_list)

# Calculate Top-1 accuracy
top1_accuracy = top_k_accuracy(predictions_tensor, ground_truth_tensor, k=1)
print(f"Top-1 Accuracy: {top1_accuracy*100:.2f}%")

# Calculate F1 score
f1 = f1_score(ground_truth_tensor.numpy(), predictions_tensor.numpy(), average='weighted')
print(f"F1 Score: {f1:.2f}")

# Calculate mAP (mean Average Precision)
ap_scores = []
num_classes = len(set(ground_truth_tensor.numpy()))  # Assuming ground truth contains class labels
for i in range(num_classes):
    ap = average_precision_score(ground_truth_tensor.numpy() == i, predictions_tensor.numpy() == i)
    ap_scores.append(ap)

mAP = sum(ap_scores) / len(ap_scores)
print(f"mAP: {mAP:.2f}")

"""### Appendix - Other Training Trials

#### Training Model with Chairs and Dining Tables together

Trial 58 (BAD):
Adding onto trial 57, changing model to yolov8m, and reducing learning rate to 0.0005, increasing batch rate to 10, reducing conf to 0.1, freezing first 10 layers as backbone, reduced image size to 512, changed degrees to 5 to decrease rotation for chairs changed scale to 0.25 to decrease scaling changed mixup to 0.2 to increase mixup enabled copy_paste augmentation to 0.2
"""

### Trial 58 ###

model = YOLO('yolov8m.pt')

results = model.train(
    data='coco/custom_coco.yaml',
    epochs=50,  # Increase epochs
    imgsz=512,  # Reduce image size
    batch=10,  # Increase batch size
    device="mps",
    amp=True,
    cache=True,
    max_det=100,
    conf=0.1,  # Lower confidence threshold
    iou=0.6,  # Adjust IoU threshold
    optimizer='AdamW',
    lr0=0.0005,  # Adjust learning rate
    cos_lr=True,  # Enable cosine learning rate decay
    momentum=0.9,
    weight_decay=0.001,
    augment=True,  # Enable data augmentation
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=5,  # decrease rotation
    translate=0.1,
    scale=0.25,  # decrease scaling
    flipud=0.0,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.2,  # Increase mixup
    copy_paste=0.2,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=2.0,
)

### Trial 58: Compare trained model best.pt with YOLO8m.pt ###

# Load the original model
model_original = YOLO('yolov8m.pt')
metrics_original = model_original.val(data='coco/custom_coco.yaml')

# Load the best checkpoint from train56
model_train60 = YOLO('runs/detect/train60/weights/best.pt')
metrics_train60 = model_train60.val(data='coco/custom_coco.yaml')

# Compare mAP50
print(f"Original mAP50: {metrics_original.box.map50}")
print(f"Train56 mAP50: {metrics_train60.box.map50}")

"""#### Training Model with just Chairs (Previous trials before selecting best model)

Trial 59 - Training model with only chairs (BAD): The goal is to improve the detection of chairs first, and then implement dining tables since the histogram is skewed to the left for chairs

Trial 60 - Training model with only chairs v2: Changed learning rate to 0.001, and brought in augmentation values, increased the # of images.

Trial 61 - Training model with only chairs v3: BEST as of 2:00 pm, 21/03

Trial 62 - Training the chairs model using GPU now v4

Trial 63 - Training the chairs model to improve it (BAD)

Trial 64 - Training the chairs model with original yolov8m to check to see if it improves over my model (BEST as of 11:02 pm, 21/03) (train in detect)

Trial 65 - Training the chairs model with best.pt from Trial 64 (Train2 in detect) higher batch size, lower confidence, higher learning rate, increase scaling, increase rotation, increase mix-up, increase copy-paste.

Trial 67 - double learning rate, double batch size, increase epochs, increase max_det by 25, increase workers, reduce rotation to 15, adding more augmentation etc.

Trial 66 - seeing if changing augmentation with Yolov8l provides better results (Does provide better results than m - BEST 03/23, 3:00 pm)

Trial 75 - Training Chairs with Yolov8x with more augmentation and higher conf (Worse than trial 70 - previous train with Yolov8X)
"""

### Trial 59

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8s.pt') # runs/detect/train43/weights/best.pt

results = model.train(
    data='coco/test_coco.yaml',
    epochs=50,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=10,  # Reduce batch size to prevent memory overload
    device="mps",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=100,  # Lower max detections per image to avoid NMS time limits, prev = 100
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.5,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.001,  # Lower learning rate to avoid overshooting
    #cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #hsv_h=0.015,
    #hsv_s=0.7,
    #hsv_v=0.4,
    #degrees=5,  # decrease rotation
    #translate=0.1,
    #scale=0.25,  # decrease scaling
    #flipud=0.0,
    #fliplr=0.5,
    mosaic=1.0,
    mixup=0.2,  # Increase mixup
    copy_paste=0.2,  # Enable copy-paste augmentation
    agnostic_nms=True,
    #freeze=10,
)

### Trial 60

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8s.pt') # runs/detect/train43/weights/best.pt

results = model.train(
    data='coco/test_coco.yaml',
    epochs=50,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=10,  # Reduce batch size to prevent memory overload
    device="mps",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=100,  # Lower max detections per image to avoid NMS time limits, prev = 100
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.4,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    #cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    freeze=0,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=5,  # decrease rotation
    translate=0.1,
    scale=0.25,  # decrease scaling
    flipud=0.0,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.2,  # Increase mixup
    copy_paste=0.2,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=2.0,
)

### Trial 61

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8m.pt') # runs/detect/train43/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=50,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=12,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    workers=8,
    max_det=100,  # Lower max detections per image to avoid NMS time limits, prev = 100
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.4,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    freeze=0,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=5,  # decrease rotation
    translate=0.1,
    scale=0.25,  # decrease scaling
    flipud=0.1,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.2,  # Increase mixup
    copy_paste=0.2,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=2.0,
    patience=25, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_chairs_val2017/000000000139.jpg')
results = model.predict(source=image_path, conf=0.25)
results[0].show()  # Access the first result and show the image

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load the original YOLOv8 model
model_original = YOLO("yolov8m.pt")
metrics_original = model_original.val(data=os.path.join(drive_root, "test_coco.yaml"))

# Load the best checkpoint from training (update train folder number)
best_model_path = "/content/runs/detect/train3/weights/best.pt"
model_train3 = YOLO(best_model_path)
metrics_train3 = model_train3.val(data=os.path.join(drive_root, "test_coco.yaml"))

# Extract mAP50 scores
# Ensure you're accessing the correct part of the metrics dictionary or object
map50_original = metrics_original.box.map50  # Access mAP50 for the original model
map50_train3 = metrics_train3.box.map50  # Access mAP50 for your trained model

# Print the mAP50 comparison
print(f"Original mAP50: {map50_original}")
print(f"Train3 mAP50: {map50_train3}")

### Trial 62
# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train3/weights/best.pt') # runs/detect/train43/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=50,  # Increase epochs for longer training
    imgsz=512,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    workers=8,
    max_det=100,  # Lower max detections per image to avoid NMS time limits, prev = 100
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.4,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0005,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    freeze=10,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=5,  # decrease rotation
    translate=0.1,
    scale=0.25,  # decrease scaling
    flipud=0.1,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.2,  # Increase mixup
    copy_paste=0.2,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=2.0,
    patience=25, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

# Check for the full path of the file
import os

file_name = 'best.pt'  # Example: file you want to locate
for root, dirs, files in os.walk('/content/runs/detect'):
    if file_name in files:
        print(f"File {file_name} found at: {os.path.join(root, file_name)}")

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_chairs_val2017/000000000139.jpg')
results = model.predict(source=image_path, conf=0.25)
results[0].show()  # Access the first result and show the image

### Trial 63
# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt') # runs/detect/train43/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=65,  # Increase epochs for longer training
    imgsz=512,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    workers=6,
    max_det=125,  # Lower max detections per image to avoid NMS time limits, prev = 100
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.4,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    freeze=5,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=10,  # decrease rotation
    translate=0.1,
    scale=0.25,  # decrease scaling
    flipud=0.5,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.2,  # Increase mixup
    copy_paste=0.2,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=2.0,
    patience=20, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

### Trial 64
# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8m') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=100,  # Increase epochs for longer training
    imgsz=512,  # Try reducing image size if NMS issues persist
    batch=12,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache='disk',  # Cache images to speed up training
    max_det=125,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=2,
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.4,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0005,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    #cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    freeze=0,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=5,  # decrease rotation
    translate=0.1,
    scale=0.25,  # decrease scaling
    flipud=0.1,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.2,  # Increase mixup
    copy_paste=0.2,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=2.0,
    patience=50, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_chairs_val2017/000000000139.jpg')
results = model.predict(source=image_path, conf=0.25)
results[0].show()  # Access the first result and show the image

### Trial 65
# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train/weights/best.pt') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=100,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=32,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=150,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=2,
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.45,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0005,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    freeze=3,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=30,  # increase rotation
    translate=0.2,
    scale=0.9,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.8,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=False,
    cls=3.0,
    patience=35, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_chairs_val2017/000000000139.jpg')
results = model.predict(source=image_path, conf=0.25)
results[0].show()  # Access the first result and show the image

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load the original YOLOv8 model
best_model_path = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train/weights/best.pt"
model_train = YOLO(best_model_path)
metrics_train = model_train.val(data=os.path.join(drive_root, "test_coco.yaml"))

# Load the best checkpoint from training (update train folder number)
latest_model_path = "/content/runs/detect/train3/weights/best.pt"
model_train3 = YOLO(latest_model_path)
metrics_train3 = model_train3.val(data=os.path.join(drive_root, "test_coco.yaml"))

# Extract mAP50 scores
# Ensure you're accessing the correct part of the metrics dictionary or object
map50_train = metrics_train.box.map50  # Access mAP50 for the original model
map50_train3 = metrics_train3.box.map50  # Access mAP50 for your trained model

# Print the mAP50 comparison
print(f"Train mAP50: {map50_train}")
print(f"Train3 mAP50: {map50_train3}")

### Trial 67
# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best/weights/best.pt') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=150,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=175,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=2,
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.45,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    freeze=5,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=45,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.5,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.8,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    patience=50, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

### Trial 66 ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8l') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=100,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=150,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=2,
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.45,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=20,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.6,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    patience=35, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_chairs_val2017/000000000139.jpg')
results = model.predict(source=image_path, conf=0.25)
results[0].show()  # Access the first result and show the image

### Trial 75 ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8x') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "test_coco.yaml"),
    epochs=150,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=200,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=12,
    conf=0.75,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.5,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=45,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.6,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    box=0.5,  # Reduced bounding box loss gain
    patience=30, # Number of epochs with no improvement before stopping (increase or decrease)
    #save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_both_val2017/000000000139.jpg') ### Try Mosaic for validation testing
results = model.predict(source=image_path, conf=0.25)
results[0].show()  # Access the first result and show the image

"""#### Training the best chairs model with dining tables now (Previous trials before pivot to training both classes separately)

Trial 68 - Using same initial Conditions as Trial 66

Trial 69 - Training the chairs model with dining tables now v2 - more augmentation, changing learning rate, and increasing # of images for training

Trial 71 - Training Dining table with Yolov8x, increasing Iou, and conf, with 6000 images (3000 chairs, 3000 dining tables)

Train 72 - Training dining table with yolov8x, with greater IOU and conf, and more data augmentation, but mAP not improving
"""

### Trial 68 ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best/weights/best.pt') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "custom_coco.yaml"),
    epochs=100,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=175,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=2,
    conf=0.25,  # Lower confidence threshold for more detections, maybe make this more stringent to improve results (maybe 0.45), increase training data size, increase epochs
    iou=0.45,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    #single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=20,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.6,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    box=0.05,  # Reduced bounding box loss gain
    patience=35, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_chairs_val2017/000000000139.jpg') ### Try Mosaic for validation testing
results = model.predict(source=image_path, conf=0.25)
results[0].show()  # Access the first result and show the image

### Trial 69 ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best/weights/best.pt') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "custom_coco.yaml"),
    epochs=125,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=200,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=2,
    conf=0.25,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.45,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    #single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=30,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.4,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.7,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    box=0.05,  # Reduced bounding box loss gain
    patience=25, # Number of epochs with no improvement before stopping (increase or decrease)
    save_period=10,  # Save the model after every 10 epochs
)

### Trial 71 ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best/weights/best.pt') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "custom_coco.yaml"),
    epochs=150,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=175,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=8,
    conf=0.7,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.45,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    #single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=30,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.6,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    #box=0.5,  # Reduced bounding box loss gain
    patience=20, # Number of epochs with no improvement before stopping (increase or decrease)
    #save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_both_val2017/000000000139.jpg') ### Try Mosaic for validation testing
results = model.predict(source=image_path, conf=0.7)
results[0].show()  # Access the first result and show the image

### Trial 72 ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/best/weights/best.pt') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "custom_coco.yaml"),
    epochs=150,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=175,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=8,
    conf=0.7,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.45,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    #single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=30,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.6,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    #box=0.5,  # Reduced bounding box loss gain
    patience=20, # Number of epochs with no improvement before stopping (increase or decrease)
    #save_period=10,  # Save the model after every 10 epochs
)

"""#### Training just Dining Tables to have 2 models, 1 for chairs and 1 for tables
Train 73 - just dining tables, using conditions of trial 70 (Best Chair Model)
"""

### Trial 73 ###

# Define Google Drive path
drive_root = "/content/drive/MyDrive/Colab Notebooks/ME6402 Project/coco/"

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8x') # /content/drive/MyDrive/Colab Notebooks/ME6402 Project/runs/detect/train4/weights/best.pt

results = model.train(
    data=os.path.join(drive_root, "table_coco.yaml"),
    epochs=150,  # Increase epochs for longer training
    imgsz=640,  # Try reducing image size if NMS issues persist
    batch=16,  # Reduce batch size to prevent memory overload
    device="cuda",  # Keep MPS backend if using a Mac
    amp=True,  # Enable mixed precision
    cache=True,  # Cache images to speed up training
    max_det=200,  # Lower max detections per image to avoid NMS time limits, prev = 100
    workers=10,
    conf=0.7,  # Lower confidence threshold for more detections, prev = 0.25
    iou=0.5,  # Standard IoU threshold
    optimizer='AdamW',  # Use AdamW optimizer
    lr0=0.0001,  # Lower learning rate to avoid overshooting
    lrf=0.01,
    cos_lr=True,  # Enables cosine learning rate decay
    momentum=0.9,  # Default momentum, prev = 0.9
    weight_decay=0.001,  # Weight decay for regularization
    augment=True,  # Enable data augmentation
    #freeze=3,
    single_cls=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=30,  # increase rotation
    translate=0.2,
    scale=0.8,  # increase scaling
    flipud=0.3,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.6,  # Increase mixup
    copy_paste=0.5,  # Enable copy-paste augmentation
    agnostic_nms=True,
    cls=3.0,
    box=0.5,  # Reduced bounding box loss gain
    patience=25, # Number of epochs with no improvement before stopping (increase or decrease)
    #save_period=10,  # Save the model after every 10 epochs
)

# Correctly join the file path and pass the conf parameter separately
image_path = os.path.join(drive_root, 'images/subset250_both_val2017/000000000139.jpg') ### Try Mosaic for validation testing
results = model.predict(source=image_path, conf=0.7)
results[0].show()  # Access the first result and show the image